{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep \n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_accept_cookies():\n",
    "    \n",
    "    driver = webdriver.Chrome('chromedriver')\n",
    "    URL = \"http://books.toscrape.com/\"\n",
    "    driver.get(URL)\n",
    "\n",
    "    #sleep(3)\n",
    "    #accept_cookies = driver.find_elements_by_xpath('/html/body/div[7]/div[3]/div/div[1]/div/div[2]/div/button[1]')\n",
    "\n",
    "    #for i in accept_cookies:\n",
    "    #    if i.text == \"Accept and Continue\":\n",
    "    #        relevant_button = i\n",
    "    #relevant_button.click()\n",
    "    return driver\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "def get_properties():\n",
    "    driver = load_and_accept_cookies()\n",
    "\n",
    "    \n",
    "\n",
    "    book_container = driver.find_element_by_xpath('/html/body/div/div/div/div/section/div[2]/ol')\n",
    "    book_container_properties = driver.find_elements_by_class_name('image_container')\n",
    "\n",
    "   \n",
    "    prop_nums = len(book_container_properties)\n",
    "    #print(prop_nums)\n",
    "\n",
    "\n",
    "    data = {\"Name\": [], \"UPC\": [], \"Product_Type\": [],\n",
    "        \"Price_excl_tax\": [], \"Price_incl_tax\": [], \"Tax\":[],\t\n",
    "        \"Availability\":[],\"reviews_no\":[] \n",
    "        }\n",
    "\n",
    "    #csv_columns = [\"Name\", \"UPC\", \"Product_Type\",\n",
    "    #    \"Price_excl_tax\", \"Price_incl_tax\", \"Tax\",\t\n",
    "    #    \"Availability\",\"reviews_no\"]\n",
    "    \n",
    "    for i in range(prop_nums):\n",
    "        book_container = driver.find_element_by_xpath('/html/body/div/div/div/div/section/div[2]/ol')\n",
    "        books = book_container.find_elements_by_class_name('image_container')[i]\n",
    "        books.click()\n",
    "        sleep(3)\n",
    "\n",
    "        bk_name_elem = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/article/div[1]/div[2]/h1')\n",
    "        data['Name'].append(bk_name_elem.text)\n",
    "        \n",
    "\n",
    "\n",
    "        bk_upc_elm = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/article/table/tbody/tr[1]/td')\n",
    "        data['UPC'].append(bk_upc_elm.text)\n",
    "\n",
    "        bk_product_type_elem = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/article/table/tbody/tr[2]/td')\n",
    "        data['Product_Type'].append(bk_product_type_elem.text)\n",
    "\n",
    "\n",
    "\n",
    "        bk_price_excl_elem = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/article/table/tbody/tr[3]/td')\n",
    "        excl_price = bk_price_excl_elem.text[1:]\n",
    "        data['Price_excl_tax'].append(excl_price)\n",
    "\n",
    "\n",
    "        bk_price_incl_elem = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/article/table/tbody/tr[4]/td')\n",
    "        incl_price = bk_price_excl_elem.text[1:]\n",
    "        data['Price_incl_tax'].append(incl_price)\n",
    "\n",
    "        bk_tax_elem = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/article/table/tbody/tr[5]/td')\n",
    "        tax_price = bk_tax_elem.text[1:]\n",
    "        data['Tax'].append(tax_price)\n",
    "\n",
    "        bk_availability_elem = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/article/table/tbody/tr[5]/td')\n",
    "        bk_availablity = bk_availability_elem.text[10:11]\n",
    "        data['Availability'].append(bk_availablity)\n",
    "\n",
    "        bk_reviews_elem = driver.find_element_by_xpath('/html/body/div/div/div[2]/div[2]/article/table/tbody/tr[7]/td')\n",
    "        data['reviews_no'].append(bk_reviews_elem.text)\n",
    "\n",
    "        sleep(1)\n",
    "        \n",
    "        driver.back()\n",
    "        df = pd.DataFrame.from_dict(data)\n",
    "        df.to_csv('test.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        #try:\n",
    "        #    with open('test.csv','w') as csv_file:\n",
    "        #        writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "        #        writer.writeheader()\n",
    "        #        for value in data.items():\n",
    "        #                writer.writerow(data)\n",
    "        #except IOError:\n",
    "        #    print(\"I/O ERROR\")    \n",
    "\n",
    "        \n",
    "        \n",
    "       # if i == (0):\n",
    "            #driver.find_element_by_xpath('/html/body/div/div/div/div/section/div[2]/div/ul/li[2]/a').click\n",
    "            #next_page.click()\n",
    "            #i = 0\n",
    "            #print(data)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "get_properties() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import csv\n",
    "with open('test.csv',newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        print(','.join(row))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ",Name,UPC,Product_Type,Price_excl_tax,Price_incl_tax,Tax,Availability,reviews_no\n",
      "0,A Light in the Attic,a897fe39b1053632,Books,51.77,51.77,0.00,,0\n",
      "1,Tipping the Velvet,90fa61229261140a,Books,53.74,53.74,0.00,,0\n",
      "2,Soumission,6957f44c3847a760,Books,50.10,50.10,0.00,,0\n",
      "3,Sharp Objects,e00eb4fd7b871a48,Books,47.82,47.82,0.00,,0\n",
      "4,Sapiens: A Brief History of Humankind,4165285e1663650f,Books,54.23,54.23,0.00,,0\n",
      "5,The Requiem Red,f77dbf2323deb740,Books,22.65,22.65,0.00,,0\n",
      "6,The Dirty Little Secrets of Getting Your Dream Job,2597b5a345f45e1b,Books,33.34,33.34,0.00,,0\n",
      "7,The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull,e72a5dfc7e9267b2,Books,17.93,17.93,0.00,,0\n",
      "8,The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics,e10e1e165dc8be4a,Books,22.60,22.60,0.00,,0\n",
      "9,The Black Maria,1dfe412b8ac00530,Books,52.15,52.15,0.00,,0\n",
      "10,Starving Hearts (Triangular Trade Trilogy, #1),0312262ecafa5a40,Books,13.99,13.99,0.00,,0\n",
      "11,Shakespeare's Sonnets,30a7f60cd76ca58c,Books,20.66,20.66,0.00,,0\n",
      "12,Set Me Free,ce6396b0f23f6ecc,Books,17.46,17.46,0.00,,0\n",
      "13,Scott Pilgrim's Precious Little Life (Scott Pilgrim #1),3b1c02bac2a429e6,Books,52.29,52.29,0.00,,0\n",
      "14,Rip it Up and Start Again,a34ba96d4081e6a4,Books,35.02,35.02,0.00,,0\n",
      "15,Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991,deda3e61b9514b83,Books,57.25,57.25,0.00,,0\n",
      "16,Olio,feb7cc7701ecf901,Books,23.88,23.88,0.00,,0\n",
      "17,Mesaerion: The Best Science Fiction Stories 1800-1849,e30f54cea9b38190,Books,37.59,37.59,0.00,,0\n",
      "18,Libertarianism for Beginners,a18a4f574854aced,Books,51.33,51.33,0.00,,0\n",
      "19,It's Only the Himalayas,a22124811bfa8350,Books,45.17,45.17,0.00,,0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('aicore': conda)"
  },
  "interpreter": {
   "hash": "a5dd17061b3d829ee04cc955e1699132345e592827be092a83c5a29ecbe4f213"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}